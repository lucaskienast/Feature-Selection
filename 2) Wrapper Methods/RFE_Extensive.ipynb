{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFE Extensive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfT6mznTHs1m"
      },
      "source": [
        "# RFE: Recursive Feature Elimination \n",
        "\n",
        "## Wrapper Methods for Feature Selection \n",
        "\n",
        "RFE is popular for feature selection because it is easy to configure and use and because it is effective at selecting those features (columns) in a training dataset that are more or most relevant in predicting the target variable.\n",
        "\n",
        "There are two important configuration options when using RFE: the choice in the number of features to select and the choice of the algorithm used to help choose features. Both of these hyperparameters can be explored, although the performance of the method is not strongly dependent on these hyperparameters being configured well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkGCwmhDKWnb"
      },
      "source": [
        "## Theory\n",
        "\n",
        "A machine learning dataset for classification or regression is comprised of rows and columns, like an excel spreadsheet. Rows are often referred to as samples and columns are referred to as features, e.g. features of an observation in a problem domain.\n",
        "\n",
        "Feature selection refers to techniques that select a subset of the most relevant features (columns) for a dataset. Fewer features can allow machine learning algorithms to run more efficiently (less space or time complexity) and be more effective. Some machine learning algorithms can be misled by irrelevant input features, resulting in worse predictive performance.\n",
        "\n",
        "RFE is a wrapper-type feature selection algorithm. This means that a different machine learning algorithm is given and used in the core of the method, is wrapped by RFE, and used to help select features. This is in contrast to filter-based feature selections that score each feature and select those features with the largest (or smallest) score. Technically, RFE is a wrapper-style feature selection algorithm that also uses filter-based feature selection internally. \n",
        "\n",
        "RFE works by searching for a subset of features by starting with all features in the training dataset and successfully removing features until the desired number remains. This is achieved by fitting the given machine learning algorithm used in the core of the model, ranking features by importance, discarding the least important features, and re-fitting the model. This process is repeated until a specified number of features remains. Features are scored either using the provided machine learning model (e.g. some algorithms like decision trees offer importance scores) or by using a statistical method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgSdQgs2Lr3d"
      },
      "source": [
        "## Application\n",
        "\n",
        "The scikit-learn Python machine learning library provides an implementation of RFE for machine learning. RFE is a transform. To use it, first the class is configured with the chosen algorithm specified via the “estimator” argument and the number of features to select via the “n_features_to_select” argument.\n",
        "\n",
        "The algorithm must provide a way to calculate important scores, such as a decision tree. The algorithm used in RFE does not have to be the algorithm that is fit on the selected features; different algorithms can be used. Once configured, the class must be fit on a training dataset to select the features by calling the fit() function. After the class is fit, the choice of input variables can be seen via the “support_” attribute that provides a True or False for each input variable. It can then be applied to the training and test datasets by calling the transform() function.\n",
        "\n",
        "It is common to use k-fold cross-validation to evaluate a machine learning algorithm on a dataset. When using cross-validation, it is good practice to perform data transforms like RFE as part of a Pipeline to avoid data leakage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B8XrQx6MSPJ"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpDaACwgC-K3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BRMgzoJMlKN"
      },
      "source": [
        "## RFE for Classification\n",
        "\n",
        "First, we can use the make_classification() function to create a synthetic binary classification problem with 1,000 examples and 10 input features, five of which are important and five of which are redundant.\n",
        "\n",
        "Next, we can evaluate an RFE feature selection algorithm on this dataset. We will use a DecisionTreeClassifier to choose features and set the number of features to five. We will then fit a new DecisionTreeClassifier model on the selected features.\n",
        "\n",
        "We will evaluate the model using repeated stratified k-fold cross-validation, with three repeats and 10 folds. We will report the mean and standard deviation of the accuracy of the model across all repeats and folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sckCrB5-Mfqi",
        "outputId": "155ec251-e088-4b98-a4e0-dd752f576aa9"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsZ4VhSM8J5"
      },
      "source": [
        "# create pipeline\n",
        "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
        "model = DecisionTreeClassifier()\n",
        "pipeline = Pipeline(steps=[('s',rfe),('m',model)])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px8Syde-M-Ip"
      },
      "source": [
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3JwK2HiNB45",
        "outputId": "d9f56589-1195-4ade-9157-b575e2f997ed"
      },
      "source": [
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.887 (0.026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1rlOF_qNNrU"
      },
      "source": [
        "We can also use the RFE model pipeline as a final model and make predictions for classification.\n",
        "\n",
        "First, the RFE and model are fit on all available data, then the predict() function can be called to make predictions on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSrevwtsNF-p",
        "outputId": "b85d504a-b219-4ea2-ace7-f3064098a594"
      },
      "source": [
        "# fit the model on all available data\n",
        "pipeline.fit(X, y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('s',\n",
              "                 RFE(estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                      class_weight=None,\n",
              "                                                      criterion='gini',\n",
              "                                                      max_depth=None,\n",
              "                                                      max_features=None,\n",
              "                                                      max_leaf_nodes=None,\n",
              "                                                      min_impurity_decrease=0.0,\n",
              "                                                      min_impurity_split=None,\n",
              "                                                      min_samples_leaf=1,\n",
              "                                                      min_samples_split=2,\n",
              "                                                      min_weight_fraction_leaf=0.0,\n",
              "                                                      presort='deprecated',\n",
              "                                                      random_state=None,\n",
              "                                                      splitter='best'),\n",
              "                     n_fe...o_select=5, step=1, verbose=0)),\n",
              "                ('m',\n",
              "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                        criterion='gini', max_depth=None,\n",
              "                                        max_features=None, max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        presort='deprecated', random_state=None,\n",
              "                                        splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxhTsFL5NVcL",
        "outputId": "ad9b78e2-fc26-4ab9-ac7e-a4e1cb26395f"
      },
      "source": [
        "# make a prediction for one example\n",
        "data = [[2.56999479,-0.13019997,3.16075093,-4.35936352,-1.61271951,-1.39352057,-2.48924933,-1.93094078,3.26130366,2.05692145]]\n",
        "yhat = pipeline.predict(data)\n",
        "print('Predicted Class: %d' % (yhat))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ2pkdXxOBU0"
      },
      "source": [
        "Running the example fits the RFE pipeline on the entire dataset and is then used to make a prediction on a new row of data, as we might when using the model in an application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jgwqWbCOFvH"
      },
      "source": [
        "## RFE for Regression\n",
        "\n",
        "First, we can use the make_regression() function to create a synthetic regression problem with 1,000 examples and 10 input features, five of which are important and five of which are redundant.\n",
        "\n",
        "Next, we can evaluate an RFE algorithm on this dataset. As we did with the last section, we will evaluate the pipeline with a decision tree using repeated k-fold cross-validation, with three repeats and 10 folds.\n",
        "\n",
        "We will report the mean absolute error (MAE) of the model across all repeats and folds. The scikit-learn library makes the MAE negative so that it is maximized instead of minimized. This means that larger negative MAE are better and a perfect model has a MAE of 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3OH-WDyOFlA",
        "outputId": "b884c408-d7a4-4981-cfa3-cf25ca4321a8"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mkX-5poNYcU"
      },
      "source": [
        "# create pipeline\n",
        "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5)\n",
        "model = DecisionTreeRegressor()\n",
        "pipeline = Pipeline(steps=[('s',rfe),('m',model)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgc2-tnBOzFG"
      },
      "source": [
        "# evaluate model\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1gDD61lO1Tk",
        "outputId": "9a06d221-85bf-4cee-a540-370426229646"
      },
      "source": [
        "# report performance\n",
        "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: -27.090 (2.600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1x0BjAFP4MP"
      },
      "source": [
        "We can also use the RFE model pipeline as a final model and make predictions for regression.\n",
        "\n",
        "First, the Pipeline is fit on all available data, then the predict() function can be called to make predictions on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp08vZxpP8Kw",
        "outputId": "9a16429f-a93c-4af3-e233-336cb653ccaf"
      },
      "source": [
        "# fit the model on all available data\n",
        "pipeline.fit(X, y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('s',\n",
              "                 RFE(estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
              "                                                     criterion='mse',\n",
              "                                                     max_depth=None,\n",
              "                                                     max_features=None,\n",
              "                                                     max_leaf_nodes=None,\n",
              "                                                     min_impurity_decrease=0.0,\n",
              "                                                     min_impurity_split=None,\n",
              "                                                     min_samples_leaf=1,\n",
              "                                                     min_samples_split=2,\n",
              "                                                     min_weight_fraction_leaf=0.0,\n",
              "                                                     presort='deprecated',\n",
              "                                                     random_state=None,\n",
              "                                                     splitter='best'),\n",
              "                     n_features_to_select=5, step=1, verbose=0)),\n",
              "                ('m',\n",
              "                 DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                       max_depth=None, max_features=None,\n",
              "                                       max_leaf_nodes=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=1, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       presort='deprecated', random_state=None,\n",
              "                                       splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urfZdB-8QAsy",
        "outputId": "22eba7c6-9fd3-4856-aa47-6caa23d0e45c"
      },
      "source": [
        "# make a prediction for one example\n",
        "data = [[-2.02220122,0.31563495,0.82797464,-0.30620401,0.16003707,-1.44411381,0.87616892,-0.50446586,0.23009474,0.76201118]]\n",
        "yhat = pipeline.predict(data)\n",
        "print('Predicted: %.3f' % (yhat))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: -84.288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMzzQbUTQHKD"
      },
      "source": [
        "Running the example fits the RFE pipeline on the entire dataset and is then used to make a prediction on a new row of data, as we might when using the model in an application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM5PVWLwQJ7I"
      },
      "source": [
        "## RFE Hyperparameters\n",
        "\n",
        "In this section, we will take a closer look at some of the hyperparameters you should consider tuning for the RFE method for feature selection and their effect on model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip65zg02QP5x"
      },
      "source": [
        "### Explore number of features\n",
        "\n",
        "An important hyperparameter for the RFE algorithm is the number of features to select.\n",
        "\n",
        "In the previous section, we used an arbitrary number of selected features, five, which matches the number of informative features in the synthetic dataset. In practice, we cannot know the best number of features to select with RFE; instead, it is good practice to test different values.\n",
        "\n",
        "The example below demonstrates selecting different numbers of features from 2 to 10 on the synthetic binary classification dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHybvNXDQBLj"
      },
      "source": [
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "\treturn X, y"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbyxcgKFTLzZ"
      },
      "source": [
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(2, 10):\n",
        "\t\trfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
        "\t\tmodel = DecisionTreeClassifier()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBXaR_BuTN_J"
      },
      "source": [
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfANTb4TQnh"
      },
      "source": [
        "# define dataset\n",
        "X, y = get_dataset()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2joddqv6TSjJ"
      },
      "source": [
        "# get the models to evaluate\n",
        "models = get_models()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWTol5jrTUjP",
        "outputId": "df02b500-501c-491b-bb3e-896a80cdca31"
      },
      "source": [
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">2 0.720 (0.038)\n",
            ">3 0.815 (0.040)\n",
            ">4 0.873 (0.033)\n",
            ">5 0.889 (0.029)\n",
            ">6 0.885 (0.031)\n",
            ">7 0.887 (0.027)\n",
            ">8 0.887 (0.027)\n",
            ">9 0.885 (0.027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "BLnru5eETYy_",
        "outputId": "73556c1c-f0a2-4484-a9ba-8160310d55f5"
      },
      "source": [
        "# plot model performance for comparison\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.boxplot(results, labels=names, showmeans=True)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8TCbeq_TjbK"
      },
      "source": [
        "Running the example first reports the mean accuracy for each configured number of input features.\n",
        "\n",
        "In this case, we can see that performance improves as the number of features increase and perhaps peaks around 4-to-7 as we might expect, given that only five features are relevant to the target variable.\n",
        "\n",
        "A box and whisker plot is created for the distribution of accuracy scores for each configured number of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWmpM6mQTrMz"
      },
      "source": [
        "### Automatically select the number of features\n",
        "\n",
        "It is also possible to automatically select the number of features chosen by RFE.\n",
        "\n",
        "This can be achieved by performing cross-validation evaluation of different numbers of features as we did in the previous section and automatically selecting the number of features that resulted in the best mean score.\n",
        "\n",
        "The RFECV class implements this for us.\n",
        "\n",
        "The RFECV is configured just like the RFE class regarding the choice of the algorithm that is wrapped. Additionally, the minimum number of features to be considered can be specified via the “min_features_to_select” argument (defaults to 1) and we can also specify the type of cross-validation and scoring to use via the “cv” (defaults to 5) and “scoring” arguments (uses accuracy for classification).\n",
        "\n",
        "We can demonstrate this on our synthetic binary classification problem and use RFECV in our pipeline instead of RFE to automatically choose the number of selected features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-jhf2WiTg_i"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nbj3_O_UBRO"
      },
      "source": [
        "# create pipeline\n",
        "rfe = RFECV(estimator=DecisionTreeClassifier())\n",
        "model = DecisionTreeClassifier()\n",
        "pipeline = Pipeline(steps=[('s',rfe),('m',model)])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDQBR8DxUDdY"
      },
      "source": [
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWVkeGbDULdX",
        "outputId": "590df871-0fe0-4dbf-d42e-c8b0da996013"
      },
      "source": [
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.889 (0.029)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_aPUX0_UQ6V"
      },
      "source": [
        "Running the example reports the mean and standard deviation accuracy of the model.\n",
        "\n",
        "In this case, we can see the RFE that uses a decision tree and automatically selects a number of features and then fits a decision tree on the selected features achieves a classification accuracy of about 88.2 percent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMmNoznWUY4L"
      },
      "source": [
        "### Which features were selected\n",
        "\n",
        "When using RFE, we may be interested to know which features were selected and which were removed.\n",
        "\n",
        "This can be achieved by reviewing the attributes of the fit RFE object (or fit RFECV object). The “support_” attribute reports true or false as to which features in order of column index were included and the “ranking_” attribute reports the relative ranking of features in the same order.\n",
        "\n",
        "The example below fits an RFE model on the whole dataset and selects five features, then reports each feature column index (0 to 9), whether it was selected or not (True or False), and the relative feature ranking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHa1RaQRUNuw"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEcmLcNuUqTx"
      },
      "source": [
        "# define RFE\n",
        "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpeZ_safUrv7",
        "outputId": "13f627ce-bfcf-42bb-db5e-58d93791fa68"
      },
      "source": [
        "# fit RFE\n",
        "rfe.fit(X, y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFE(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                     criterion='gini', max_depth=None,\n",
              "                                     max_features=None, max_leaf_nodes=None,\n",
              "                                     min_impurity_decrease=0.0,\n",
              "                                     min_impurity_split=None,\n",
              "                                     min_samples_leaf=1, min_samples_split=2,\n",
              "                                     min_weight_fraction_leaf=0.0,\n",
              "                                     presort='deprecated', random_state=None,\n",
              "                                     splitter='best'),\n",
              "    n_features_to_select=5, step=1, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otf-suJZUtRD",
        "outputId": "bc4aa5bf-69f8-487f-c6b3-03a102228b45"
      },
      "source": [
        "# summarize all features\n",
        "for i in range(X.shape[1]):\n",
        "\tprint('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: 0, Selected False, Rank: 4.000\n",
            "Column: 1, Selected False, Rank: 5.000\n",
            "Column: 2, Selected True, Rank: 1.000\n",
            "Column: 3, Selected True, Rank: 1.000\n",
            "Column: 4, Selected True, Rank: 1.000\n",
            "Column: 5, Selected False, Rank: 6.000\n",
            "Column: 6, Selected True, Rank: 1.000\n",
            "Column: 7, Selected False, Rank: 2.000\n",
            "Column: 8, Selected True, Rank: 1.000\n",
            "Column: 9, Selected False, Rank: 3.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PkzFmmjU1NI"
      },
      "source": [
        "Running the example lists of the 10 input features and whether or not they were selected as well as their relative ranking of importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY9QWCUXU5BN"
      },
      "source": [
        "### Explore base algorithm\n",
        "\n",
        "There are many algorithms that can be used in the core RFE, as long as they provide some indication of variable importance.\n",
        "\n",
        "Most decision tree algorithms are likely to report the same general trends in feature importance, but this is not guaranteed. It might be helpful to explore the use of different algorithms wrapped by RFE.\n",
        "\n",
        "The example below demonstrates how you might explore this configuration option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hi_RSbvUtkq"
      },
      "source": [
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "\treturn X, y"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds_xLVg3VPlm"
      },
      "source": [
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\t# lr\n",
        "\trfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
        "\tmodel = DecisionTreeClassifier()\n",
        "\tmodels['lr'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\t# perceptron\n",
        "\trfe = RFE(estimator=Perceptron(), n_features_to_select=5)\n",
        "\tmodel = DecisionTreeClassifier()\n",
        "\tmodels['per'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\t# cart\n",
        "\trfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
        "\tmodel = DecisionTreeClassifier()\n",
        "\tmodels['cart'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\t# rf\n",
        "\trfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=5)\n",
        "\tmodel = DecisionTreeClassifier()\n",
        "\tmodels['rf'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\t# gbm\n",
        "\trfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)\n",
        "\tmodel = DecisionTreeClassifier()\n",
        "\tmodels['gbm'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtNl-KiCVVCg"
      },
      "source": [
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85jAZLHpVZmw"
      },
      "source": [
        "# define dataset\n",
        "X, y = get_dataset()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkc8Qt7_VbTx"
      },
      "source": [
        "# get the models to evaluate\n",
        "models = get_models()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r8NK30kVdII",
        "outputId": "74b1fd85-935f-4d8e-d453-d2d82517b79b"
      },
      "source": [
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">lr 0.895 (0.032)\n",
            ">per 0.848 (0.036)\n",
            ">cart 0.885 (0.028)\n",
            ">rf 0.856 (0.038)\n",
            ">gbm 0.886 (0.031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "s4eW4JzoVfYQ",
        "outputId": "e9d6b89f-1d4d-46ce-f845-ae55a785737d"
      },
      "source": [
        "# plot model performance for comparison\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.boxplot(results, labels=names, showmeans=True)\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g10g04QbVvxL"
      },
      "source": [
        "Running the example first reports the mean accuracy for each wrapped algorithm.\n",
        "\n",
        "In this case, the results suggest that linear algorithms like logistic regression might select better features more reliably than the chosen decision tree and ensemble of decision tree algorithms.\n",
        "\n",
        "A box and whisker plot is created for the distribution of accuracy scores for each configured wrapped algorithm.\n",
        "\n",
        "We can see the general trend of good performance with logistic regression, CART and perhaps GBM. This highlights that even though the actual model used to fit the chosen features is the same in each case, the model used within RFE can make an important difference to which features are selected and in turn the performance on the prediction problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzqPfsJBV_Vb"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}
